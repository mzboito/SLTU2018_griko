08/02 21:35:16 label: griko best setup 1
08/02 21:35:16 description:
  temp = 1
08/02 21:35:16 /home/getalp/zanonbom/seq2seq/translate/__main__.py ../SLTU_griko/models/grapheme/random_split/rand4/config_grapheme.yaml --train -v
08/02 21:35:16 commit hash d7914bbb0f1dc22438de0e15b82ebec43e0614ff
08/02 21:35:16 tensorflow version: 1.8.0
08/02 21:35:16 program arguments
08/02 21:35:16   aggregation_method   'concat'
08/02 21:35:16   align_encoder_id     0
08/02 21:35:16   allow_growth         True
08/02 21:35:16   attention_type       'global'
08/02 21:35:16   attn_filter_length   0
08/02 21:35:16   attn_filters         0
08/02 21:35:16   attn_prev_word       False
08/02 21:35:16   attn_size            12
08/02 21:35:16   attn_temperature     1
08/02 21:35:16   attn_window_size     0
08/02 21:35:16   average              False
08/02 21:35:16   baseline_activation  None
08/02 21:35:16   baseline_learning_rate 0.001
08/02 21:35:16   baseline_optimizer   'adam'
08/02 21:35:16   baseline_steps       0
08/02 21:35:16   batch_mode           'standard'
08/02 21:35:16   batch_size           32
08/02 21:35:16   beam_size            1
08/02 21:35:16   bidir                True
08/02 21:35:16   bidir_projection     False
08/02 21:35:16   binary               False
08/02 21:35:16   cell_size            12
08/02 21:35:16   cell_type            'LSTM'
08/02 21:35:16   character_level      False
08/02 21:35:16   checkpoints          []
08/02 21:35:16   conditional_rnn      False
08/02 21:35:16   config               '../SLTU_griko/models/grapheme/random_split/rand4/config_grapheme.yaml'
08/02 21:35:16   convolutions         None
08/02 21:35:16   data_dir             '../SLTU_griko/models/grapheme/random_split/files/'
08/02 21:35:16   debug                False
08/02 21:35:16   decay_after_n_epoch  0
08/02 21:35:16   decay_every_n_epoch  None
08/02 21:35:16   decay_if_no_progress None
08/02 21:35:16   decoders             [{'name': 'gr'}]
08/02 21:35:16   description          'temp = 1'
08/02 21:35:16   dev_prefix           ['dev.rand4', 'train.rand4']
08/02 21:35:16   embedding_dropout    0.0
08/02 21:35:16   embedding_initializer None
08/02 21:35:16   embedding_size       12
08/02 21:35:16   embedding_weight_scale None
08/02 21:35:16   encoders             [{'name': 'it'}]
08/02 21:35:16   ensemble             False
08/02 21:35:16   eval_burn_in         0
08/02 21:35:16   feed_previous        0.0
08/02 21:35:16   final_state          'last'
08/02 21:35:16   freeze_variables     []
08/02 21:35:16   generate_first       True
08/02 21:35:16   gpu_id               0
08/02 21:35:16   highway_layers       0
08/02 21:35:16   initial_state_dropout 0.5
08/02 21:35:16   initializer          None
08/02 21:35:16   input_layer_dropout  0.0
08/02 21:35:16   input_layers         None
08/02 21:35:16   keep_best            4
08/02 21:35:16   keep_every_n_hours   0
08/02 21:35:16   label                'griko best setup 1'
08/02 21:35:16   layer_norm           False
08/02 21:35:16   layers               1
08/02 21:35:16   learning_rate        0.001
08/02 21:35:16   learning_rate_decay_factor 1.0
08/02 21:35:16   len_normalization    1.0
08/02 21:35:16   log_file             'log_griko.txt'
08/02 21:35:16   loss_function        'xent'
08/02 21:35:16   max_dev_size         0
08/02 21:35:16   max_epochs           0
08/02 21:35:16   max_gradient_norm    5.0
08/02 21:35:16   max_len              128
08/02 21:35:16   max_steps            150000
08/02 21:35:16   max_test_size        0
08/02 21:35:16   max_to_keep          1
08/02 21:35:16   max_train_size       0
08/02 21:35:16   maxout_stride        None
08/02 21:35:16   mem_fraction         1.0
08/02 21:35:16   min_learning_rate    1e-06
08/02 21:35:16   model_dir            '../SLTU_griko/models/grapheme/random_split/rand4/model/'
08/02 21:35:16   moving_average       None
08/02 21:35:16   no_gpu               False
08/02 21:35:16   optimizer            'adam'
08/02 21:35:16   orthogonal_init      False
08/02 21:35:16   output               None
08/02 21:35:16   output_dropout       0.0
08/02 21:35:16   parallel_iterations  16
08/02 21:35:16   pervasive_dropout    False
08/02 21:35:16   pooling_avg          True
08/02 21:35:16   post_process_script  None
08/02 21:35:16   pred_deep_layer      False
08/02 21:35:16   pred_edits           False
08/02 21:35:16   pred_embed_proj      False
08/02 21:35:16   pred_maxout_layer    True
08/02 21:35:16   purge                False
08/02 21:35:16   raw_output           False
08/02 21:35:16   read_ahead           10
08/02 21:35:16   reconstruction_attn_weight 0.05
08/02 21:35:16   reconstruction_decoders False
08/02 21:35:16   reconstruction_weight 1.0
08/02 21:35:16   reinforce_after_n_epoch None
08/02 21:35:16   remove_unk           False
08/02 21:35:16   reverse              False
08/02 21:35:16   reverse_input        False
08/02 21:35:16   reward_function      'sentence_bleu'
08/02 21:35:16   rnn_feed_attn        True
08/02 21:35:16   rnn_input_dropout    0.5
08/02 21:35:16   rnn_output_dropout   0.0
08/02 21:35:16   rnn_state_dropout    0.0
08/02 21:35:16   save                 False
08/02 21:35:16   score_function       'corpus_bleu'
08/02 21:35:16   score_functions      ['bleu', 'loss']
08/02 21:35:16   script_dir           'scripts'
08/02 21:35:16   sgd_after_n_epoch    None
08/02 21:35:16   sgd_learning_rate    1.0
08/02 21:35:16   shuffle              True
08/02 21:35:16   softmax_temperature  1.0
08/02 21:35:16   steps_per_checkpoint 10000
08/02 21:35:16   steps_per_eval       10000
08/02 21:35:16   swap_memory          True
08/02 21:35:16   tie_embeddings       False
08/02 21:35:16   time_pooling         None
08/02 21:35:16   train                True
08/02 21:35:16   train_initial_states True
08/02 21:35:16   train_prefix         'train.rand4'
08/02 21:35:16   truncate_lines       True
08/02 21:35:16   update_first         False
08/02 21:35:16   use_baseline         False
08/02 21:35:16   use_dropout          True
08/02 21:35:16   use_lstm             True
08/02 21:35:16   use_lstm_full_state  False
08/02 21:35:16   use_previous_word    True
08/02 21:35:16   verbose              True
08/02 21:35:16   vocab_prefix         'vocab.rand4'
08/02 21:35:16   weight_scale         0.1
08/02 21:35:16   word_dropout         0.0
08/02 21:35:16 python random seed: 4090898149102369519
08/02 21:35:16 tf random seed:     1156054697884808081
08/02 21:35:16 creating model
08/02 21:35:16 using device: /gpu:0
08/02 21:35:16 copying vocab to ../SLTU_griko/models/grapheme/random_split/rand4/model/data/vocab.it
08/02 21:35:16 copying vocab to ../SLTU_griko/models/grapheme/random_split/rand4/model/data/vocab.gr
08/02 21:35:16 reading vocabularies
08/02 21:35:16 creating model
08/02 21:35:26 model parameters (27)
08/02 21:35:26   baseline_step:0 ()
08/02 21:35:26   decoder_gr/attention_it/U_a/kernel:0 (24, 12)
08/02 21:35:26   decoder_gr/attention_it/W_a/bias:0 (12,)
08/02 21:35:26   decoder_gr/attention_it/W_a/kernel:0 (12, 12)
08/02 21:35:26   decoder_gr/attention_it/v_a:0 (12,)
08/02 21:35:26   decoder_gr/basic_lstm_cell/bias:0 (48,)
08/02 21:35:26   decoder_gr/basic_lstm_cell/kernel:0 (48, 48)
08/02 21:35:26   decoder_gr/it/initial_state_projection/bias:0 (24,)
08/02 21:35:26   decoder_gr/it/initial_state_projection/kernel:0 (12, 24)
08/02 21:35:26   decoder_gr/maxout/bias:0 (12,)
08/02 21:35:26   decoder_gr/maxout/kernel:0 (48, 12)
08/02 21:35:26   decoder_gr/softmax1/bias:0 (44,)
08/02 21:35:26   decoder_gr/softmax1/kernel:0 (6, 44)
08/02 21:35:26   embedding_gr:0 (44, 12)
08/02 21:35:26   embedding_it:0 (457, 12)
08/02 21:35:26   encoder_it/initial_state_bw:0 (24,)
08/02 21:35:26   encoder_it/initial_state_fw:0 (24,)
08/02 21:35:26   encoder_it/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/basic_lstm_cell/bias:0 (48,)
08/02 21:35:26   encoder_it/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/basic_lstm_cell/kernel:0 (24, 48)
08/02 21:35:26   encoder_it/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/basic_lstm_cell/bias:0 (48,)
08/02 21:35:26   encoder_it/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/basic_lstm_cell/kernel:0 (24, 48)
08/02 21:35:26   global_step:0 ()
08/02 21:35:26   initial_state_keep_prob:0 ()
08/02 21:35:26   initial_state_keep_prob_1:0 ()
08/02 21:35:26   learning_rate:0 ()
08/02 21:35:26   rnn_input_keep_prob:0 ()
08/02 21:35:26   rnn_input_keep_prob_1:0 ()
08/02 21:35:26 number of parameters: 0.01M
08/02 21:35:26 global step: 0
08/02 21:35:26 baseline step: 0
08/02 21:35:26 reading training data
08/02 21:35:26 total line count: 297
08/02 21:35:26 files: ../SLTU_griko/models/grapheme/random_split/files/train.rand4.it ../SLTU_griko/models/grapheme/random_split/files/train.rand4.gr
08/02 21:35:26 lines reads: 297
08/02 21:35:26 reading development data
08/02 21:35:26 files: ../SLTU_griko/models/grapheme/random_split/files/dev.rand4.it ../SLTU_griko/models/grapheme/random_split/files/dev.rand4.gr
08/02 21:35:26 lines reads: 33
08/02 21:35:26 files: ../SLTU_griko/models/grapheme/random_split/files/train.rand4.it ../SLTU_griko/models/grapheme/random_split/files/train.rand4.gr
08/02 21:35:26 lines reads: 297
08/02 21:35:27 starting training
08/02 21:54:57 step 10000 epoch 1078 learning rate 0.001 step-time 0.116 loss 83.178
08/02 21:54:57 starting evaluation
08/02 21:54:57 dev.rand4 bleu=12.23 loss=53.35 penalty=0.926 ratio=0.928
08/02 21:55:00 train.rand4 bleu=13.36 loss=58.54 penalty=0.906 ratio=0.910
08/02 21:55:00 saving model to ../SLTU_griko/models/grapheme/random_split/rand4/model/checkpoints
08/02 21:55:00 finished saving model
08/02 21:55:00 new best model
08/02 22:14:30 step 20000 epoch 2155 learning rate 0.001 step-time 0.116 loss 70.803
08/02 22:14:30 starting evaluation
08/02 22:14:30 dev.rand4 bleu=16.33 loss=51.04 penalty=0.956 ratio=0.957
08/02 22:14:33 train.rand4 bleu=18.74 loss=51.75 penalty=0.969 ratio=0.969
08/02 22:14:33 saving model to ../SLTU_griko/models/grapheme/random_split/rand4/model/checkpoints
08/02 22:14:33 finished saving model
08/02 22:14:33 new best model
08/02 22:34:02 step 30000 epoch 3233 learning rate 0.001 step-time 0.116 loss 67.233
08/02 22:34:02 starting evaluation
08/02 22:34:02 dev.rand4 bleu=18.85 loss=50.95 penalty=0.926 ratio=0.928
08/02 22:34:05 train.rand4 bleu=20.13 loss=49.18 penalty=0.923 ratio=0.926
08/02 22:34:05 saving model to ../SLTU_griko/models/grapheme/random_split/rand4/model/checkpoints
08/02 22:34:05 finished saving model
08/02 22:34:05 new best model
08/02 22:53:34 step 40000 epoch 4310 learning rate 0.001 step-time 0.116 loss 65.430
08/02 22:53:34 starting evaluation
08/02 22:53:34 dev.rand4 bleu=23.00 loss=51.62 penalty=0.926 ratio=0.928
08/02 22:53:37 train.rand4 bleu=21.29 loss=47.00 penalty=0.934 ratio=0.936
08/02 22:53:37 saving model to ../SLTU_griko/models/grapheme/random_split/rand4/model/checkpoints
08/02 22:53:37 finished saving model
08/02 22:53:37 new best model
08/02 23:13:11 step 50000 epoch 5388 learning rate 0.001 step-time 0.116 loss 64.277
08/02 23:13:11 starting evaluation
08/02 23:13:11 dev.rand4 bleu=20.93 loss=53.00 penalty=0.956 ratio=0.957
08/02 23:13:14 train.rand4 bleu=21.78 loss=45.86 penalty=0.951 ratio=0.952
08/02 23:13:14 saving model to ../SLTU_griko/models/grapheme/random_split/rand4/model/checkpoints
08/02 23:13:14 finished saving model
08/02 23:32:46 step 60000 epoch 6465 learning rate 0.001 step-time 0.116 loss 63.354
08/02 23:32:46 starting evaluation
08/02 23:32:46 dev.rand4 bleu=23.01 loss=54.60 penalty=0.955 ratio=0.956
08/02 23:32:49 train.rand4 bleu=22.79 loss=44.79 penalty=0.944 ratio=0.946
08/02 23:32:49 saving model to ../SLTU_griko/models/grapheme/random_split/rand4/model/checkpoints
08/02 23:32:49 finished saving model
08/02 23:32:49 new best model
08/02 23:52:18 step 70000 epoch 7543 learning rate 0.001 step-time 0.116 loss 62.762
08/02 23:52:18 starting evaluation
08/02 23:52:18 dev.rand4 bleu=23.28 loss=55.46 penalty=0.920 ratio=0.923
08/02 23:52:21 train.rand4 bleu=23.03 loss=44.44 penalty=0.907 ratio=0.911
08/02 23:52:21 saving model to ../SLTU_griko/models/grapheme/random_split/rand4/model/checkpoints
08/02 23:52:21 finished saving model
08/02 23:52:21 new best model
08/03 00:11:51 step 80000 epoch 8620 learning rate 0.001 step-time 0.116 loss 62.317
08/03 00:11:51 starting evaluation
08/03 00:11:52 dev.rand4 bleu=25.40 loss=55.78 penalty=0.964 ratio=0.965
08/03 00:11:54 train.rand4 bleu=23.34 loss=44.60 penalty=0.925 ratio=0.928
08/03 00:11:54 saving model to ../SLTU_griko/models/grapheme/random_split/rand4/model/checkpoints
08/03 00:11:54 finished saving model
08/03 00:11:54 new best model
08/03 00:31:22 step 90000 epoch 9697 learning rate 0.001 step-time 0.115 loss 61.863
08/03 00:31:22 starting evaluation
08/03 00:31:22 dev.rand4 bleu=23.26 loss=56.29 penalty=0.991 ratio=0.991
08/03 00:31:25 train.rand4 bleu=23.72 loss=43.71 penalty=0.919 ratio=0.922
08/03 00:31:25 saving model to ../SLTU_griko/models/grapheme/random_split/rand4/model/checkpoints
08/03 00:31:25 finished saving model
08/03 00:50:55 step 100000 epoch 10775 learning rate 0.001 step-time 0.116 loss 61.479
08/03 00:50:55 starting evaluation
08/03 00:50:55 dev.rand4 bleu=24.48 loss=55.12 penalty=0.995 ratio=0.995
08/03 00:50:58 train.rand4 bleu=24.71 loss=43.07 penalty=0.965 ratio=0.965
08/03 00:50:58 saving model to ../SLTU_griko/models/grapheme/random_split/rand4/model/checkpoints
08/03 00:50:58 finished saving model
08/03 01:10:23 step 110000 epoch 11852 learning rate 0.001 step-time 0.115 loss 61.206
08/03 01:10:23 starting evaluation
08/03 01:10:23 dev.rand4 bleu=24.25 loss=55.80 penalty=0.952 ratio=0.954
08/03 01:10:26 train.rand4 bleu=24.57 loss=42.89 penalty=0.977 ratio=0.977
08/03 01:10:26 saving model to ../SLTU_griko/models/grapheme/random_split/rand4/model/checkpoints
08/03 01:10:26 finished saving model
08/03 01:29:58 step 120000 epoch 12930 learning rate 0.001 step-time 0.116 loss 60.941
08/03 01:29:58 starting evaluation
08/03 01:29:58 dev.rand4 bleu=23.86 loss=56.44 penalty=0.950 ratio=0.951
08/03 01:30:01 train.rand4 bleu=24.04 loss=42.79 penalty=0.947 ratio=0.949
08/03 01:30:01 saving model to ../SLTU_griko/models/grapheme/random_split/rand4/model/checkpoints
08/03 01:30:01 finished saving model
08/03 01:49:32 step 130000 epoch 14007 learning rate 0.001 step-time 0.116 loss 60.662
08/03 01:49:32 starting evaluation
08/03 01:49:32 dev.rand4 bleu=23.04 loss=55.96 penalty=0.977 ratio=0.977
08/03 01:49:35 train.rand4 bleu=25.58 loss=42.67 penalty=0.954 ratio=0.955
08/03 01:49:35 saving model to ../SLTU_griko/models/grapheme/random_split/rand4/model/checkpoints
08/03 01:49:35 finished saving model
08/03 02:09:07 step 140000 epoch 15085 learning rate 0.001 step-time 0.116 loss 60.490
08/03 02:09:07 starting evaluation
08/03 02:09:08 dev.rand4 bleu=23.53 loss=55.91 penalty=0.925 ratio=0.927
08/03 02:09:10 train.rand4 bleu=25.67 loss=42.33 penalty=0.951 ratio=0.952
08/03 02:09:10 saving model to ../SLTU_griko/models/grapheme/random_split/rand4/model/checkpoints
08/03 02:09:10 finished saving model
08/03 02:29:37 step 150000 epoch 16162 learning rate 0.001 step-time 0.121 loss 60.268
08/03 02:29:37 starting evaluation
08/03 02:29:37 dev.rand4 bleu=22.69 loss=56.01 penalty=0.978 ratio=0.979
08/03 02:29:41 train.rand4 bleu=25.44 loss=41.81 penalty=0.984 ratio=0.984
08/03 02:29:41 saving model to ../SLTU_griko/models/grapheme/random_split/rand4/model/checkpoints
08/03 02:29:41 finished saving model
08/03 02:29:41 finished training
08/03 02:29:41 exiting...
08/03 02:29:41 saving model to ../SLTU_griko/models/grapheme/random_split/rand4/model/checkpoints
08/03 02:29:41 finished saving model
