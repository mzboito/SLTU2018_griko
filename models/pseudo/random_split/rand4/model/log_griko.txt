08/01 14:20:02 label: griko best setup 1
08/01 14:20:02 description:
  temp = 1
08/01 14:20:02 /home/getalp/zanonbom/seq2seq/translate/__main__.py ../SLTU_griko/models/pseudo/random_split/rand4/config_pseudo.yaml --train -v
08/01 14:20:02 commit hash d7914bbb0f1dc22438de0e15b82ebec43e0614ff
08/01 14:20:02 tensorflow version: 1.8.0
08/01 14:20:02 program arguments
08/01 14:20:02   aggregation_method   'concat'
08/01 14:20:02   align_encoder_id     0
08/01 14:20:02   allow_growth         True
08/01 14:20:02   attention_type       'global'
08/01 14:20:02   attn_filter_length   0
08/01 14:20:02   attn_filters         0
08/01 14:20:02   attn_prev_word       False
08/01 14:20:02   attn_size            12
08/01 14:20:02   attn_temperature     1
08/01 14:20:02   attn_window_size     0
08/01 14:20:02   average              False
08/01 14:20:02   baseline_activation  None
08/01 14:20:02   baseline_learning_rate 0.001
08/01 14:20:02   baseline_optimizer   'adam'
08/01 14:20:02   baseline_steps       0
08/01 14:20:02   batch_mode           'standard'
08/01 14:20:02   batch_size           32
08/01 14:20:02   beam_size            1
08/01 14:20:02   bidir                True
08/01 14:20:02   bidir_projection     False
08/01 14:20:02   binary               False
08/01 14:20:02   cell_size            12
08/01 14:20:02   cell_type            'LSTM'
08/01 14:20:02   character_level      False
08/01 14:20:02   checkpoints          []
08/01 14:20:02   conditional_rnn      False
08/01 14:20:02   config               '../SLTU_griko/models/pseudo/random_split/rand4/config_pseudo.yaml'
08/01 14:20:02   convolutions         None
08/01 14:20:02   data_dir             '../SLTU_griko/models/pseudo/random_split/files/'
08/01 14:20:02   debug                False
08/01 14:20:02   decay_after_n_epoch  0
08/01 14:20:02   decay_every_n_epoch  None
08/01 14:20:02   decay_if_no_progress None
08/01 14:20:02   decoders             [{'name': 'ph'}]
08/01 14:20:02   description          'temp = 1'
08/01 14:20:02   dev_prefix           ['dev.rand4', 'train.rand4']
08/01 14:20:02   embedding_dropout    0.0
08/01 14:20:02   embedding_initializer None
08/01 14:20:02   embedding_size       12
08/01 14:20:02   embedding_weight_scale None
08/01 14:20:02   encoders             [{'name': 'it'}]
08/01 14:20:02   ensemble             False
08/01 14:20:02   eval_burn_in         0
08/01 14:20:02   feed_previous        0.0
08/01 14:20:02   final_state          'last'
08/01 14:20:02   freeze_variables     []
08/01 14:20:02   generate_first       True
08/01 14:20:02   gpu_id               0
08/01 14:20:02   highway_layers       0
08/01 14:20:02   initial_state_dropout 0.5
08/01 14:20:02   initializer          None
08/01 14:20:02   input_layer_dropout  0.0
08/01 14:20:02   input_layers         None
08/01 14:20:02   keep_best            4
08/01 14:20:02   keep_every_n_hours   0
08/01 14:20:02   label                'griko best setup 1'
08/01 14:20:02   layer_norm           False
08/01 14:20:02   layers               1
08/01 14:20:02   learning_rate        0.001
08/01 14:20:02   learning_rate_decay_factor 1.0
08/01 14:20:02   len_normalization    1.0
08/01 14:20:02   log_file             'log_griko.txt'
08/01 14:20:02   loss_function        'xent'
08/01 14:20:02   max_dev_size         0
08/01 14:20:02   max_epochs           0
08/01 14:20:02   max_gradient_norm    5.0
08/01 14:20:02   max_len              128
08/01 14:20:02   max_steps            150000
08/01 14:20:02   max_test_size        0
08/01 14:20:02   max_to_keep          1
08/01 14:20:02   max_train_size       0
08/01 14:20:02   maxout_stride        None
08/01 14:20:02   mem_fraction         1.0
08/01 14:20:02   min_learning_rate    1e-06
08/01 14:20:02   model_dir            '../SLTU_griko/models/pseudo/random_split/rand4/model/'
08/01 14:20:02   moving_average       None
08/01 14:20:02   no_gpu               False
08/01 14:20:02   optimizer            'adam'
08/01 14:20:02   orthogonal_init      False
08/01 14:20:02   output               None
08/01 14:20:02   output_dropout       0.0
08/01 14:20:02   parallel_iterations  16
08/01 14:20:02   pervasive_dropout    False
08/01 14:20:02   pooling_avg          True
08/01 14:20:02   post_process_script  None
08/01 14:20:02   pred_deep_layer      False
08/01 14:20:02   pred_edits           False
08/01 14:20:02   pred_embed_proj      False
08/01 14:20:02   pred_maxout_layer    True
08/01 14:20:02   purge                False
08/01 14:20:02   raw_output           False
08/01 14:20:02   read_ahead           10
08/01 14:20:02   reconstruction_attn_weight 0.05
08/01 14:20:02   reconstruction_decoders False
08/01 14:20:02   reconstruction_weight 1.0
08/01 14:20:02   reinforce_after_n_epoch None
08/01 14:20:02   remove_unk           False
08/01 14:20:02   reverse              False
08/01 14:20:02   reverse_input        False
08/01 14:20:02   reward_function      'sentence_bleu'
08/01 14:20:02   rnn_feed_attn        True
08/01 14:20:02   rnn_input_dropout    0.5
08/01 14:20:02   rnn_output_dropout   0.0
08/01 14:20:02   rnn_state_dropout    0.0
08/01 14:20:02   save                 False
08/01 14:20:02   score_function       'corpus_bleu'
08/01 14:20:02   score_functions      ['bleu', 'loss']
08/01 14:20:02   script_dir           'scripts'
08/01 14:20:02   sgd_after_n_epoch    None
08/01 14:20:02   sgd_learning_rate    1.0
08/01 14:20:02   shuffle              True
08/01 14:20:02   softmax_temperature  1.0
08/01 14:20:02   steps_per_checkpoint 10000
08/01 14:20:02   steps_per_eval       10000
08/01 14:20:02   swap_memory          True
08/01 14:20:02   tie_embeddings       False
08/01 14:20:02   time_pooling         None
08/01 14:20:02   train                True
08/01 14:20:02   train_initial_states True
08/01 14:20:02   train_prefix         'train.rand4'
08/01 14:20:02   truncate_lines       True
08/01 14:20:02   update_first         False
08/01 14:20:02   use_baseline         False
08/01 14:20:02   use_dropout          True
08/01 14:20:02   use_lstm             True
08/01 14:20:02   use_lstm_full_state  False
08/01 14:20:02   use_previous_word    True
08/01 14:20:02   verbose              True
08/01 14:20:02   vocab_prefix         'vocab.rand4'
08/01 14:20:02   weight_scale         0.1
08/01 14:20:02   word_dropout         0.0
08/01 14:20:02 python random seed: 4768175353295688753
08/01 14:20:02 tf random seed:     5219728567299081553
08/01 14:20:02 creating model
08/01 14:20:02 using device: /gpu:0
08/01 14:20:02 copying vocab to ../SLTU_griko/models/pseudo/random_split/rand4/model/data/vocab.it
08/01 14:20:02 copying vocab to ../SLTU_griko/models/pseudo/random_split/rand4/model/data/vocab.ph
08/01 14:20:02 reading vocabularies
08/01 14:20:02 creating model
08/01 14:20:11 model parameters (27)
08/01 14:20:11   baseline_step:0 ()
08/01 14:20:11   decoder_ph/attention_it/U_a/kernel:0 (24, 12)
08/01 14:20:11   decoder_ph/attention_it/W_a/bias:0 (12,)
08/01 14:20:11   decoder_ph/attention_it/W_a/kernel:0 (12, 12)
08/01 14:20:11   decoder_ph/attention_it/v_a:0 (12,)
08/01 14:20:11   decoder_ph/basic_lstm_cell/bias:0 (48,)
08/01 14:20:11   decoder_ph/basic_lstm_cell/kernel:0 (48, 48)
08/01 14:20:11   decoder_ph/it/initial_state_projection/bias:0 (24,)
08/01 14:20:11   decoder_ph/it/initial_state_projection/kernel:0 (12, 24)
08/01 14:20:11   decoder_ph/maxout/bias:0 (12,)
08/01 14:20:11   decoder_ph/maxout/kernel:0 (48, 12)
08/01 14:20:11   decoder_ph/softmax1/bias:0 (56,)
08/01 14:20:11   decoder_ph/softmax1/kernel:0 (6, 56)
08/01 14:20:11   embedding_it:0 (451, 12)
08/01 14:20:11   embedding_ph:0 (56, 12)
08/01 14:20:11   encoder_it/initial_state_bw:0 (24,)
08/01 14:20:11   encoder_it/initial_state_fw:0 (24,)
08/01 14:20:11   encoder_it/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/basic_lstm_cell/bias:0 (48,)
08/01 14:20:11   encoder_it/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/basic_lstm_cell/kernel:0 (24, 48)
08/01 14:20:11   encoder_it/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/basic_lstm_cell/bias:0 (48,)
08/01 14:20:11   encoder_it/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/basic_lstm_cell/kernel:0 (24, 48)
08/01 14:20:11   global_step:0 ()
08/01 14:20:11   initial_state_keep_prob:0 ()
08/01 14:20:11   initial_state_keep_prob_1:0 ()
08/01 14:20:11   learning_rate:0 ()
08/01 14:20:11   rnn_input_keep_prob:0 ()
08/01 14:20:11   rnn_input_keep_prob_1:0 ()
08/01 14:20:11 number of parameters: 0.01M
08/01 14:20:12 global step: 0
08/01 14:20:12 baseline step: 0
08/01 14:20:12 reading training data
08/01 14:20:12 total line count: 297
08/01 14:20:12 files: ../SLTU_griko/models/pseudo/random_split/files/train.rand4.it ../SLTU_griko/models/pseudo/random_split/files/train.rand4.ph
08/01 14:20:12 lines reads: 297
08/01 14:20:12 reading development data
08/01 14:20:12 files: ../SLTU_griko/models/pseudo/random_split/files/dev.rand4.it ../SLTU_griko/models/pseudo/random_split/files/dev.rand4.ph
08/01 14:20:12 lines reads: 33
08/01 14:20:12 files: ../SLTU_griko/models/pseudo/random_split/files/train.rand4.it ../SLTU_griko/models/pseudo/random_split/files/train.rand4.ph
08/01 14:20:12 lines reads: 297
08/01 14:20:12 starting training
08/01 14:36:54 step 10000 epoch 1078 learning rate 0.001 step-time 0.099 loss 67.377
08/01 14:36:54 starting evaluation
08/01 14:36:55 dev.rand4 bleu=7.71 loss=85.04 penalty=1.000 ratio=1.041
08/01 14:36:58 train.rand4 bleu=9.54 loss=53.94 penalty=1.000 ratio=1.265
08/01 14:36:58 saving model to ../SLTU_griko/models/pseudo/random_split/rand4/model/checkpoints
08/01 14:36:58 finished saving model
08/01 14:36:58 new best model
08/01 14:53:41 step 20000 epoch 2155 learning rate 0.001 step-time 0.099 loss 62.752
08/01 14:53:41 starting evaluation
08/01 14:53:41 dev.rand4 bleu=10.15 loss=89.57 penalty=0.918 ratio=0.921
08/01 14:53:44 train.rand4 bleu=12.38 loss=50.99 penalty=1.000 ratio=1.182
08/01 14:53:44 saving model to ../SLTU_griko/models/pseudo/random_split/rand4/model/checkpoints
08/01 14:53:45 finished saving model
08/01 14:53:45 new best model
08/01 15:09:51 step 30000 epoch 3233 learning rate 0.001 step-time 0.095 loss 61.036
08/01 15:09:51 starting evaluation
08/01 15:09:51 dev.rand4 bleu=10.02 loss=94.14 penalty=1.000 ratio=1.090
08/01 15:09:54 train.rand4 bleu=12.13 loss=49.01 penalty=1.000 ratio=1.260
08/01 15:09:54 saving model to ../SLTU_griko/models/pseudo/random_split/rand4/model/checkpoints
08/01 15:09:54 finished saving model
08/01 15:25:05 step 40000 epoch 4310 learning rate 0.001 step-time 0.090 loss 59.906
08/01 15:25:05 starting evaluation
08/01 15:25:06 dev.rand4 bleu=8.73 loss=95.71 penalty=1.000 ratio=1.058
08/01 15:25:09 train.rand4 bleu=14.43 loss=47.96 penalty=1.000 ratio=1.145
08/01 15:25:09 saving model to ../SLTU_griko/models/pseudo/random_split/rand4/model/checkpoints
08/01 15:25:09 finished saving model
08/01 15:39:59 step 50000 epoch 5388 learning rate 0.001 step-time 0.088 loss 59.088
08/01 15:39:59 starting evaluation
08/01 15:39:59 dev.rand4 bleu=9.63 loss=96.47 penalty=1.000 ratio=1.038
08/01 15:40:02 train.rand4 bleu=15.31 loss=47.11 penalty=1.000 ratio=1.092
08/01 15:40:02 saving model to ../SLTU_griko/models/pseudo/random_split/rand4/model/checkpoints
08/01 15:40:02 finished saving model
08/01 15:54:49 step 60000 epoch 6465 learning rate 0.001 step-time 0.088 loss 58.450
08/01 15:54:49 starting evaluation
08/01 15:54:49 dev.rand4 bleu=10.84 loss=96.99 penalty=1.000 ratio=1.065
08/01 15:54:52 train.rand4 bleu=15.54 loss=46.48 penalty=1.000 ratio=1.073
08/01 15:54:52 saving model to ../SLTU_griko/models/pseudo/random_split/rand4/model/checkpoints
08/01 15:54:52 finished saving model
08/01 15:54:52 new best model
08/01 16:09:39 step 70000 epoch 7543 learning rate 0.001 step-time 0.088 loss 57.978
08/01 16:09:39 starting evaluation
08/01 16:09:40 dev.rand4 bleu=10.52 loss=98.51 penalty=1.000 ratio=1.029
08/01 16:09:43 train.rand4 bleu=16.67 loss=45.92 penalty=1.000 ratio=1.046
08/01 16:09:43 saving model to ../SLTU_griko/models/pseudo/random_split/rand4/model/checkpoints
08/01 16:09:43 finished saving model
08/01 16:24:28 step 80000 epoch 8620 learning rate 0.001 step-time 0.087 loss 57.563
08/01 16:24:28 starting evaluation
08/01 16:24:29 dev.rand4 bleu=10.28 loss=99.69 penalty=1.000 ratio=1.009
08/01 16:24:32 train.rand4 bleu=17.68 loss=45.46 penalty=1.000 ratio=1.018
08/01 16:24:32 saving model to ../SLTU_griko/models/pseudo/random_split/rand4/model/checkpoints
08/01 16:24:32 finished saving model
08/01 16:39:17 step 90000 epoch 9697 learning rate 0.001 step-time 0.087 loss 57.221
08/01 16:39:17 starting evaluation
08/01 16:39:18 dev.rand4 bleu=9.63 loss=100.37 penalty=0.889 ratio=0.895
08/01 16:39:20 train.rand4 bleu=16.76 loss=45.05 penalty=1.000 ratio=1.037
08/01 16:39:20 saving model to ../SLTU_griko/models/pseudo/random_split/rand4/model/checkpoints
08/01 16:39:20 finished saving model
08/01 16:54:08 step 100000 epoch 10775 learning rate 0.001 step-time 0.088 loss 56.901
08/01 16:54:08 starting evaluation
08/01 16:54:08 dev.rand4 bleu=10.58 loss=101.15 penalty=0.978 ratio=0.978
08/01 16:54:11 train.rand4 bleu=16.88 loss=44.68 penalty=1.000 ratio=1.045
08/01 16:54:11 saving model to ../SLTU_griko/models/pseudo/random_split/rand4/model/checkpoints
08/01 16:54:11 finished saving model
08/01 17:08:58 step 110000 epoch 11852 learning rate 0.001 step-time 0.088 loss 56.646
08/01 17:08:58 starting evaluation
08/01 17:08:59 dev.rand4 bleu=10.38 loss=101.90 penalty=1.000 ratio=1.069
08/01 17:09:02 train.rand4 bleu=16.00 loss=44.47 penalty=1.000 ratio=1.114
08/01 17:09:02 saving model to ../SLTU_griko/models/pseudo/random_split/rand4/model/checkpoints
08/01 17:09:02 finished saving model
08/01 17:23:47 step 120000 epoch 12930 learning rate 0.001 step-time 0.087 loss 56.407
08/01 17:23:47 starting evaluation
08/01 17:23:47 dev.rand4 bleu=11.01 loss=101.39 penalty=1.000 ratio=1.077
08/01 17:23:51 train.rand4 bleu=14.76 loss=44.37 penalty=1.000 ratio=1.217
08/01 17:23:51 saving model to ../SLTU_griko/models/pseudo/random_split/rand4/model/checkpoints
08/01 17:23:51 finished saving model
08/01 17:23:51 new best model
08/01 17:38:34 step 130000 epoch 14007 learning rate 0.001 step-time 0.087 loss 56.204
08/01 17:38:34 starting evaluation
08/01 17:38:34 dev.rand4 bleu=10.09 loss=102.98 penalty=0.923 ratio=0.925
08/01 17:38:37 train.rand4 bleu=16.81 loss=44.05 penalty=1.000 ratio=1.084
08/01 17:38:37 saving model to ../SLTU_griko/models/pseudo/random_split/rand4/model/checkpoints
08/01 17:38:37 finished saving model
08/01 17:53:22 step 140000 epoch 15085 learning rate 0.001 step-time 0.087 loss 56.031
08/01 17:53:22 starting evaluation
08/01 17:53:22 dev.rand4 bleu=10.21 loss=103.72 penalty=1.000 ratio=1.112
08/01 17:53:25 train.rand4 bleu=15.39 loss=43.91 penalty=1.000 ratio=1.151
08/01 17:53:25 saving model to ../SLTU_griko/models/pseudo/random_split/rand4/model/checkpoints
08/01 17:53:25 finished saving model
08/01 18:08:06 step 150000 epoch 16162 learning rate 0.001 step-time 0.087 loss 55.888
08/01 18:08:06 starting evaluation
08/01 18:08:06 dev.rand4 bleu=8.79 loss=103.48 penalty=1.000 ratio=1.131
08/01 18:08:09 train.rand4 bleu=15.26 loss=43.82 penalty=1.000 ratio=1.179
08/01 18:08:09 saving model to ../SLTU_griko/models/pseudo/random_split/rand4/model/checkpoints
08/01 18:08:09 finished saving model
08/01 18:08:09 finished training
08/01 18:08:09 exiting...
08/01 18:08:09 saving model to ../SLTU_griko/models/pseudo/random_split/rand4/model/checkpoints
08/01 18:08:09 finished saving model
