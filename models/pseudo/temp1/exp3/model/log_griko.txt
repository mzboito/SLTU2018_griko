07/24 21:28:25 label: griko best setup 1
07/24 21:28:25 description:
  temp = 1
07/24 21:28:25 /home/getalp/zanonbom/seq2seq/translate/__main__.py ../SLTU_griko/models/pseudo/temp1/exp3/config_pseudo.yaml --train -v
07/24 21:28:26 commit hash d7914bbb0f1dc22438de0e15b82ebec43e0614ff
07/24 21:28:26 tensorflow version: 1.8.0
07/24 21:28:26 program arguments
07/24 21:28:26   aggregation_method   'concat'
07/24 21:28:26   align_encoder_id     0
07/24 21:28:26   allow_growth         True
07/24 21:28:26   attention_type       'global'
07/24 21:28:26   attn_filter_length   0
07/24 21:28:26   attn_filters         0
07/24 21:28:26   attn_prev_word       False
07/24 21:28:26   attn_size            12
07/24 21:28:26   attn_temperature     1
07/24 21:28:26   attn_window_size     0
07/24 21:28:26   average              False
07/24 21:28:26   baseline_activation  None
07/24 21:28:26   baseline_learning_rate 0.001
07/24 21:28:26   baseline_optimizer   'adam'
07/24 21:28:26   baseline_steps       0
07/24 21:28:26   batch_mode           'standard'
07/24 21:28:26   batch_size           32
07/24 21:28:26   beam_size            1
07/24 21:28:26   bidir                True
07/24 21:28:26   bidir_projection     False
07/24 21:28:26   binary               False
07/24 21:28:26   cell_size            12
07/24 21:28:26   cell_type            'LSTM'
07/24 21:28:26   character_level      False
07/24 21:28:26   checkpoints          []
07/24 21:28:26   conditional_rnn      False
07/24 21:28:26   config               '../SLTU_griko/models/pseudo/temp1/exp3/config_pseudo.yaml'
07/24 21:28:26   convolutions         None
07/24 21:28:26   data_dir             '../SLTU_griko/models/pseudo/files/'
07/24 21:28:26   debug                False
07/24 21:28:26   decay_after_n_epoch  0
07/24 21:28:26   decay_every_n_epoch  None
07/24 21:28:26   decay_if_no_progress None
07/24 21:28:26   decoders             [{'name': 'ph'}]
07/24 21:28:26   description          'temp = 1'
07/24 21:28:26   dev_prefix           ['dev', 'train']
07/24 21:28:26   embedding_dropout    0.0
07/24 21:28:26   embedding_initializer None
07/24 21:28:26   embedding_size       12
07/24 21:28:26   embedding_weight_scale None
07/24 21:28:26   encoders             [{'name': 'it'}]
07/24 21:28:26   ensemble             False
07/24 21:28:26   eval_burn_in         0
07/24 21:28:26   feed_previous        0.0
07/24 21:28:26   final_state          'last'
07/24 21:28:26   freeze_variables     []
07/24 21:28:26   generate_first       True
07/24 21:28:26   gpu_id               0
07/24 21:28:26   highway_layers       0
07/24 21:28:26   initial_state_dropout 0.5
07/24 21:28:26   initializer          None
07/24 21:28:26   input_layer_dropout  0.0
07/24 21:28:26   input_layers         None
07/24 21:28:26   keep_best            4
07/24 21:28:26   keep_every_n_hours   0
07/24 21:28:26   label                'griko best setup 1'
07/24 21:28:26   layer_norm           False
07/24 21:28:26   layers               1
07/24 21:28:26   learning_rate        0.001
07/24 21:28:26   learning_rate_decay_factor 1.0
07/24 21:28:26   len_normalization    1.0
07/24 21:28:26   log_file             'log_griko.txt'
07/24 21:28:26   loss_function        'xent'
07/24 21:28:26   max_dev_size         0
07/24 21:28:26   max_epochs           0
07/24 21:28:26   max_gradient_norm    5.0
07/24 21:28:26   max_len              128
07/24 21:28:26   max_steps            150000
07/24 21:28:26   max_test_size        0
07/24 21:28:26   max_to_keep          1
07/24 21:28:26   max_train_size       0
07/24 21:28:26   maxout_stride        None
07/24 21:28:26   mem_fraction         1.0
07/24 21:28:26   min_learning_rate    1e-06
07/24 21:28:26   model_dir            '../SLTU_griko/models/pseudo/temp1/exp3/model/'
07/24 21:28:26   moving_average       None
07/24 21:28:26   no_gpu               False
07/24 21:28:26   optimizer            'adam'
07/24 21:28:26   orthogonal_init      False
07/24 21:28:26   output               None
07/24 21:28:26   output_dropout       0.0
07/24 21:28:26   parallel_iterations  16
07/24 21:28:26   pervasive_dropout    False
07/24 21:28:26   pooling_avg          True
07/24 21:28:26   post_process_script  None
07/24 21:28:26   pred_deep_layer      False
07/24 21:28:26   pred_edits           False
07/24 21:28:26   pred_embed_proj      False
07/24 21:28:26   pred_maxout_layer    True
07/24 21:28:26   purge                False
07/24 21:28:26   raw_output           False
07/24 21:28:26   read_ahead           10
07/24 21:28:26   reconstruction_attn_weight 0.05
07/24 21:28:26   reconstruction_decoders False
07/24 21:28:26   reconstruction_weight 1.0
07/24 21:28:26   reinforce_after_n_epoch None
07/24 21:28:26   remove_unk           False
07/24 21:28:26   reverse              False
07/24 21:28:26   reverse_input        False
07/24 21:28:26   reward_function      'sentence_bleu'
07/24 21:28:26   rnn_feed_attn        True
07/24 21:28:26   rnn_input_dropout    0.5
07/24 21:28:26   rnn_output_dropout   0.0
07/24 21:28:26   rnn_state_dropout    0.0
07/24 21:28:26   save                 False
07/24 21:28:26   score_function       'corpus_bleu'
07/24 21:28:26   score_functions      ['bleu', 'loss']
07/24 21:28:26   script_dir           'scripts'
07/24 21:28:26   sgd_after_n_epoch    None
07/24 21:28:26   sgd_learning_rate    1.0
07/24 21:28:26   shuffle              True
07/24 21:28:26   softmax_temperature  1.0
07/24 21:28:26   steps_per_checkpoint 10000
07/24 21:28:26   steps_per_eval       10000
07/24 21:28:26   swap_memory          True
07/24 21:28:26   tie_embeddings       False
07/24 21:28:26   time_pooling         None
07/24 21:28:26   train                True
07/24 21:28:26   train_initial_states True
07/24 21:28:26   train_prefix         'train'
07/24 21:28:26   truncate_lines       True
07/24 21:28:26   update_first         False
07/24 21:28:26   use_baseline         False
07/24 21:28:26   use_dropout          True
07/24 21:28:26   use_lstm             True
07/24 21:28:26   use_lstm_full_state  False
07/24 21:28:26   use_previous_word    True
07/24 21:28:26   verbose              True
07/24 21:28:26   vocab_prefix         'vocab'
07/24 21:28:26   weight_scale         0.1
07/24 21:28:26   word_dropout         0.0
07/24 21:28:26 python random seed: 637360962373274789
07/24 21:28:26 tf random seed:     2631758008419754892
07/24 21:28:26 creating model
07/24 21:28:26 using device: /gpu:0
07/24 21:28:26 copying vocab to ../SLTU_griko/models/pseudo/temp1/exp3/model/data/vocab.it
07/24 21:28:26 copying vocab to ../SLTU_griko/models/pseudo/temp1/exp3/model/data/vocab.ph
07/24 21:28:26 reading vocabularies
07/24 21:28:26 creating model
07/24 21:28:36 model parameters (27)
07/24 21:28:36   baseline_step:0 ()
07/24 21:28:36   decoder_ph/attention_it/U_a/kernel:0 (24, 12)
07/24 21:28:36   decoder_ph/attention_it/W_a/bias:0 (12,)
07/24 21:28:36   decoder_ph/attention_it/W_a/kernel:0 (12, 12)
07/24 21:28:36   decoder_ph/attention_it/v_a:0 (12,)
07/24 21:28:36   decoder_ph/basic_lstm_cell/bias:0 (48,)
07/24 21:28:36   decoder_ph/basic_lstm_cell/kernel:0 (48, 48)
07/24 21:28:36   decoder_ph/it/initial_state_projection/bias:0 (24,)
07/24 21:28:36   decoder_ph/it/initial_state_projection/kernel:0 (12, 24)
07/24 21:28:36   decoder_ph/maxout/bias:0 (12,)
07/24 21:28:36   decoder_ph/maxout/kernel:0 (48, 12)
07/24 21:28:36   decoder_ph/softmax1/bias:0 (56,)
07/24 21:28:36   decoder_ph/softmax1/kernel:0 (6, 56)
07/24 21:28:36   embedding_it:0 (443, 12)
07/24 21:28:36   embedding_ph:0 (56, 12)
07/24 21:28:36   encoder_it/initial_state_bw:0 (24,)
07/24 21:28:36   encoder_it/initial_state_fw:0 (24,)
07/24 21:28:36   encoder_it/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/basic_lstm_cell/bias:0 (48,)
07/24 21:28:36   encoder_it/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/basic_lstm_cell/kernel:0 (24, 48)
07/24 21:28:36   encoder_it/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/basic_lstm_cell/bias:0 (48,)
07/24 21:28:36   encoder_it/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/basic_lstm_cell/kernel:0 (24, 48)
07/24 21:28:36   global_step:0 ()
07/24 21:28:36   initial_state_keep_prob:0 ()
07/24 21:28:36   initial_state_keep_prob_1:0 ()
07/24 21:28:36   learning_rate:0 ()
07/24 21:28:36   rnn_input_keep_prob:0 ()
07/24 21:28:36   rnn_input_keep_prob_1:0 ()
07/24 21:28:36 number of parameters: 0.01M
07/24 21:28:37 global step: 0
07/24 21:28:37 baseline step: 0
07/24 21:28:37 reading training data
07/24 21:28:37 total line count: 297
07/24 21:28:37 files: ../SLTU_griko/models/pseudo/files/train.it ../SLTU_griko/models/pseudo/files/train.ph
07/24 21:28:37 lines reads: 297
07/24 21:28:37 reading development data
07/24 21:28:37 files: ../SLTU_griko/models/pseudo/files/dev.it ../SLTU_griko/models/pseudo/files/dev.ph
07/24 21:28:37 lines reads: 33
07/24 21:28:37 files: ../SLTU_griko/models/pseudo/files/train.it ../SLTU_griko/models/pseudo/files/train.ph
07/24 21:28:37 lines reads: 297
07/24 21:28:37 starting training
07/24 21:43:54 step 10000 epoch 1078 learning rate 0.001 step-time 0.091 loss 69.672
07/24 21:43:54 starting evaluation
07/24 21:43:55 dev bleu=4.99 loss=67.15 penalty=1.000 ratio=1.570
07/24 21:43:58 train bleu=8.37 loss=55.95 penalty=1.000 ratio=1.240
07/24 21:43:58 saving model to ../SLTU_griko/models/pseudo/temp1/exp3/model/checkpoints
07/24 21:43:59 finished saving model
07/24 21:43:59 new best model
07/24 22:03:29 step 20000 epoch 2155 learning rate 0.001 step-time 0.115 loss 64.846
07/24 22:03:29 starting evaluation
07/24 22:03:29 dev bleu=7.65 loss=71.79 penalty=1.000 ratio=1.036
07/24 22:03:33 train bleu=11.27 loss=52.77 penalty=1.000 ratio=1.191
07/24 22:03:33 saving model to ../SLTU_griko/models/pseudo/temp1/exp3/model/checkpoints
07/24 22:03:33 finished saving model
07/24 22:03:33 new best model
07/24 22:23:19 step 30000 epoch 3233 learning rate 0.001 step-time 0.117 loss 63.142
07/24 22:23:19 starting evaluation
07/24 22:23:19 dev bleu=8.22 loss=73.86 penalty=0.972 ratio=0.972
07/24 22:23:23 train bleu=12.79 loss=51.01 penalty=1.000 ratio=1.104
07/24 22:23:23 saving model to ../SLTU_griko/models/pseudo/temp1/exp3/model/checkpoints
07/24 22:23:24 finished saving model
07/24 22:23:24 new best model
07/24 22:43:12 step 40000 epoch 4310 learning rate 0.001 step-time 0.117 loss 62.178
07/24 22:43:12 starting evaluation
07/24 22:43:12 dev bleu=7.10 loss=75.90 penalty=1.000 ratio=1.198
07/24 22:43:16 train bleu=12.39 loss=49.81 penalty=1.000 ratio=1.187
07/24 22:43:16 saving model to ../SLTU_griko/models/pseudo/temp1/exp3/model/checkpoints
07/24 22:43:17 finished saving model
07/24 23:03:03 step 50000 epoch 5388 learning rate 0.001 step-time 0.117 loss 61.457
07/24 23:03:03 starting evaluation
07/24 23:03:04 dev bleu=8.53 loss=77.35 penalty=1.000 ratio=1.136
07/24 23:03:08 train bleu=13.32 loss=49.02 penalty=1.000 ratio=1.151
07/24 23:03:08 saving model to ../SLTU_griko/models/pseudo/temp1/exp3/model/checkpoints
07/24 23:03:08 finished saving model
07/24 23:03:08 new best model
07/24 23:22:58 step 60000 epoch 6465 learning rate 0.001 step-time 0.117 loss 60.928
07/24 23:22:58 starting evaluation
07/24 23:22:58 dev bleu=6.32 loss=78.85 penalty=1.000 ratio=1.448
07/24 23:23:02 train bleu=14.13 loss=48.36 penalty=1.000 ratio=1.117
07/24 23:23:02 saving model to ../SLTU_griko/models/pseudo/temp1/exp3/model/checkpoints
07/24 23:23:02 finished saving model
07/24 23:42:44 step 70000 epoch 7543 learning rate 0.001 step-time 0.117 loss 60.496
07/24 23:42:44 starting evaluation
07/24 23:42:44 dev bleu=7.81 loss=80.15 penalty=1.000 ratio=1.320
07/24 23:42:48 train bleu=13.14 loss=47.95 penalty=1.000 ratio=1.170
07/24 23:42:48 saving model to ../SLTU_griko/models/pseudo/temp1/exp3/model/checkpoints
07/24 23:42:48 finished saving model
07/25 00:02:34 step 80000 epoch 8620 learning rate 0.001 step-time 0.117 loss 60.151
07/25 00:02:34 starting evaluation
07/25 00:02:35 dev bleu=7.47 loss=81.09 penalty=1.000 ratio=1.238
07/25 00:02:39 train bleu=12.61 loss=47.52 penalty=1.000 ratio=1.235
07/25 00:02:39 saving model to ../SLTU_griko/models/pseudo/temp1/exp3/model/checkpoints
07/25 00:02:39 finished saving model
07/25 00:22:24 step 90000 epoch 9697 learning rate 0.001 step-time 0.117 loss 59.884
07/25 00:22:24 starting evaluation
07/25 00:22:25 dev bleu=8.67 loss=81.66 penalty=1.000 ratio=1.165
07/25 00:22:29 train bleu=14.10 loss=47.22 penalty=1.000 ratio=1.112
07/25 00:22:29 saving model to ../SLTU_griko/models/pseudo/temp1/exp3/model/checkpoints
07/25 00:22:29 finished saving model
07/25 00:22:29 new best model
07/25 00:42:16 step 100000 epoch 10775 learning rate 0.001 step-time 0.117 loss 59.631
07/25 00:42:16 starting evaluation
07/25 00:42:17 dev bleu=7.35 loss=83.13 penalty=1.000 ratio=1.465
07/25 00:42:20 train bleu=13.80 loss=46.87 penalty=1.000 ratio=1.125
07/25 00:42:20 saving model to ../SLTU_griko/models/pseudo/temp1/exp3/model/checkpoints
07/25 00:42:21 finished saving model
07/25 01:02:09 step 110000 epoch 11852 learning rate 0.001 step-time 0.117 loss 59.438
07/25 01:02:09 starting evaluation
07/25 01:02:10 dev bleu=7.99 loss=83.65 penalty=1.000 ratio=1.307
07/25 01:02:14 train bleu=14.95 loss=46.63 penalty=1.000 ratio=1.089
07/25 01:02:14 saving model to ../SLTU_griko/models/pseudo/temp1/exp3/model/checkpoints
07/25 01:02:14 finished saving model
07/25 01:21:59 step 120000 epoch 12930 learning rate 0.001 step-time 0.117 loss 59.272
07/25 01:21:59 starting evaluation
07/25 01:21:59 dev bleu=10.43 loss=83.67 penalty=1.000 ratio=1.012
07/25 01:22:03 train bleu=16.03 loss=46.43 penalty=1.000 ratio=1.021
07/25 01:22:03 saving model to ../SLTU_griko/models/pseudo/temp1/exp3/model/checkpoints
07/25 01:22:03 finished saving model
07/25 01:22:03 new best model
07/25 01:41:50 step 130000 epoch 14007 learning rate 0.001 step-time 0.117 loss 59.125
07/25 01:41:50 starting evaluation
07/25 01:41:50 dev bleu=9.81 loss=84.39 penalty=1.000 ratio=1.227
07/25 01:41:54 train bleu=15.53 loss=46.25 penalty=1.000 ratio=1.022
07/25 01:41:54 saving model to ../SLTU_griko/models/pseudo/temp1/exp3/model/checkpoints
07/25 01:41:54 finished saving model
07/25 02:01:41 step 140000 epoch 15085 learning rate 0.001 step-time 0.117 loss 58.983
07/25 02:01:41 starting evaluation
07/25 02:01:42 dev bleu=10.99 loss=84.18 penalty=1.000 ratio=1.017
07/25 02:01:45 train bleu=15.41 loss=46.09 penalty=1.000 ratio=1.040
07/25 02:01:45 saving model to ../SLTU_griko/models/pseudo/temp1/exp3/model/checkpoints
07/25 02:01:45 finished saving model
07/25 02:01:45 new best model
07/25 02:21:31 step 150000 epoch 16162 learning rate 0.001 step-time 0.117 loss 58.858
07/25 02:21:31 starting evaluation
07/25 02:21:32 dev bleu=9.76 loss=84.70 penalty=1.000 ratio=1.102
07/25 02:21:35 train bleu=16.40 loss=45.93 penalty=0.988 ratio=0.988
07/25 02:21:35 saving model to ../SLTU_griko/models/pseudo/temp1/exp3/model/checkpoints
07/25 02:21:35 finished saving model
07/25 02:21:35 finished training
07/25 02:21:35 exiting...
07/25 02:21:35 saving model to ../SLTU_griko/models/pseudo/temp1/exp3/model/checkpoints
07/25 02:21:35 finished saving model
